{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_neural_network_MNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPo/vZkfpQzPxyA48/n9l1i"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxtcQmkt276f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CONVOLUTIONAL NEURAL NETWORKS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIcale663gXg",
        "colab_type": "text"
      },
      "source": [
        "It inspects the subsets of images, learns features of image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqLrWGW33cLU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "508b5e57-5068-4475-d572-4fc2e97e67a2"
      },
      "source": [
        "!pip install tensorflow==1.14.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 90kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 33.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.28.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.0\n",
            "    Uninstalling tensorboard-2.2.0:\n",
            "      Successfully uninstalled tensorboard-2.2.0\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorflow 2.2.0rc3\n",
            "    Uninstalling tensorflow-2.2.0rc3:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc3\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuo5-fIh47BE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "e169868b-6f15-4447-9ebb-205a2f730477"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpCZQY1j5Ps7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA11-SX_5miX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "048c9ec1-b7f5-4fdf-b6b6-2d47785302ca"
      },
      "source": [
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-a839aeb82f4b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2Zp2v1p5oPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53QVowDK50vV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using Interactive session as default session so that we really do not need to go back and pass the session every single time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJF0LDE_8FOA",
        "colab_type": "text"
      },
      "source": [
        "Defining the placeholders --> x- represents the 28*28 dimensional vector\n",
        "y_ is the actual label of the image-->\n",
        "[0,1,0,0,0,0,0,0,0,0,0] - represents digit 1\n",
        "Similarly [0,0,1,0,0,0,0,0,0,0,0] - represents digit 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nEIHUKN7_zQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
        "y_ = tf.placeholder(tf.float32, [None, 10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1rU4OIp8oaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change the MNIST input data from a list of values to a 28 pixel X 28 pixel X 1 grayscale value cube\n",
        "#    which the Convolution NN can use.\n",
        "x_image = tf.reshape(x, [-1,28,28,1], name=\"x_image\")\n",
        "\n",
        "#here -1 is obviously not a valid dimension --> it is simply used as a flag to reduce it or split the image into 28*28*1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lubN4M99-Cuw",
        "colab_type": "text"
      },
      "source": [
        "**RELU as Activation Function**\n",
        "\n",
        "\n",
        "> ReLU stands for rectified linear unit, and is a type of activation function. Mathematically, it is defined as y = max(0, x).\n",
        "\n",
        "\n",
        "> https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U15auNo5AsTl",
        "colab_type": "text"
      },
      "source": [
        "**truncated_normal**\n",
        "\n",
        "> https://docs.w3cub.com/tensorflow~python/tf/truncated_normal/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMvkV5Xy9IJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define helper functions to created weights and baises variables, and convolution, and pooling layers\n",
        "#   We are using RELU as our activation function.  These must be initialized to a small positive number \n",
        "#   and with some noise so you don't end up going to zero when comparing diffs\n",
        "def weight_variable(shape):\n",
        "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "def bias_variable(shape):\n",
        "    initial = tf.constant(0.1, shape=shape)\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "#We are basically picking up the random values for weights and bias variables\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuRNivmiB0OV",
        "colab_type": "text"
      },
      "source": [
        "**Convolution and Pooling**\n",
        "\n",
        "> https://stackoverflow.com/questions/34619177/what-does-tf-nn-conv2d-do-in-tensorflow\n",
        "\n",
        "\n",
        "> Pooling all the conv values to prevent overfitting\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Bfi274oBuOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#   Convolution and Pooling - we do Convolution, and then pooling to control overfitting\n",
        "def conv2d(x, W):\n",
        "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "def max_pool_2x2(x):\n",
        "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
        "                        strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PCj4QXdFIYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define layers in the NN\n",
        "\n",
        "# 1st Convolution layer\n",
        "# 32 features for each 5X5 patch of the image\n",
        "W_conv1 = weight_variable([5, 5, 1, 32])\n",
        "b_conv1 = bias_variable([32])\n",
        "# Do convolution on images, add bias and push through RELU activation\n",
        "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
        "# take results and run through max_pool\n",
        "h_pool1 = max_pool_2x2(h_conv1)\n",
        "\n",
        "# 2nd Convolution layer\n",
        "# Process the 32 features from Convolution layer 1, in 5 X 5 patch.  Return 64 features weights and biases\n",
        "W_conv2 = weight_variable([5, 5, 32, 64])\n",
        "b_conv2 = bias_variable([64])\n",
        "# Do convolution of the output of the 1st convolution layer.  Pool results \n",
        "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
        "h_pool2 = max_pool_2x2(h_conv2)\n",
        "\n",
        "# Fully Connected Layer\n",
        "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
        "b_fc1 = bias_variable([1024])\n",
        "\n",
        "#   Connect output of pooling layer 2 as input to full connected layer\n",
        "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
        "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
        "\n",
        "# dropout some neurons to reduce overfitting\n",
        "keep_prob = tf.placeholder(tf.float32)  # get dropout probability as a training input.\n",
        "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
        "rate = 1 - keep_prob\n",
        "\n",
        "# Readout layer\n",
        "W_fc2 = weight_variable([1024, 10])\n",
        "b_fc2 = bias_variable([10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-qghI-oFVl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define model\n",
        "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlDvwzjLFY-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss measurement\n",
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_conv, labels=y_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5WCvl3vFcDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss optimization\n",
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_comoZ56FjIN",
        "colab_type": "text"
      },
      "source": [
        "**Adam Optimization**\n",
        "\n",
        "> Something better than gradient descent\n",
        "\n",
        "\n",
        "> https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTIPBSxAFhCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What is correct\n",
        "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
        "# How accurate is it?\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63KDSK-xHwA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45faefdd-49c8-4cde-91cc-5f0c4536d1b0"
      },
      "source": [
        "accuracy"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Mean_3:0' shape=() dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGO2AU2mHxCH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7eba1453-88da-4fd6-ddba-eb9b82fde7d0"
      },
      "source": [
        "correct_prediction"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Equal_1:0' shape=(?,) dtype=bool>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNlc_SGYH1R1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "import time\n",
        "\n",
        "#  define number of steps and how often we display progress\n",
        "num_steps = 3000\n",
        "display_every = 100\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg90dLNZH7iM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start timer\n",
        "start_time = time.time()\n",
        "end_time = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GelvWgEdKN6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTrI8qaEKOnU",
        "colab_type": "text"
      },
      "source": [
        "Whwn u get `FailedPreconditionError: Attempting to use uninitialized in Tensorflow` - initialize all the variables declared like below --> run the global initializer\n",
        "Stack overflow link https://stackoverflow.com/questions/34001922/failedpreconditionerror-attempting-to-use-uninitialized-in-tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBx1u1MjKCXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5uZny1iH9ye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "9f854c55-0860-4d33-8f51-45c70c793fce"
      },
      "source": [
        "import time\n",
        "\n",
        "#  define number of steps and how often we display progress\n",
        "num_steps = 3000\n",
        "display_every = 100\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "end_time = time.time()\n",
        "\n",
        "for i in range(num_steps):\n",
        "    batch = mnist.train.next_batch(50)\n",
        "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
        "\n",
        "    # Periodic status display\n",
        "    if i%display_every == 0:\n",
        "        train_accuracy = accuracy.eval(feed_dict={\n",
        "            x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
        "        end_time = time.time()\n",
        "        print(\"step {0}, elapsed time {1:.2f} seconds, training accuracy {2:.3f}%\".format(i, end_time-start_time, train_accuracy*100.0))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, elapsed time 0.28 seconds, training accuracy 14.000%\n",
            "step 100, elapsed time 15.89 seconds, training accuracy 90.000%\n",
            "step 200, elapsed time 31.42 seconds, training accuracy 90.000%\n",
            "step 300, elapsed time 47.03 seconds, training accuracy 98.000%\n",
            "step 400, elapsed time 62.62 seconds, training accuracy 94.000%\n",
            "step 500, elapsed time 78.18 seconds, training accuracy 98.000%\n",
            "step 600, elapsed time 93.68 seconds, training accuracy 92.000%\n",
            "step 700, elapsed time 109.23 seconds, training accuracy 98.000%\n",
            "step 800, elapsed time 124.74 seconds, training accuracy 98.000%\n",
            "step 900, elapsed time 140.34 seconds, training accuracy 94.000%\n",
            "step 1000, elapsed time 155.85 seconds, training accuracy 96.000%\n",
            "step 1100, elapsed time 171.50 seconds, training accuracy 100.000%\n",
            "step 1200, elapsed time 187.06 seconds, training accuracy 94.000%\n",
            "step 1300, elapsed time 202.77 seconds, training accuracy 96.000%\n",
            "step 1400, elapsed time 218.37 seconds, training accuracy 96.000%\n",
            "step 1500, elapsed time 234.02 seconds, training accuracy 100.000%\n",
            "step 1600, elapsed time 249.57 seconds, training accuracy 98.000%\n",
            "step 1700, elapsed time 265.16 seconds, training accuracy 98.000%\n",
            "step 1800, elapsed time 280.79 seconds, training accuracy 100.000%\n",
            "step 1900, elapsed time 296.34 seconds, training accuracy 98.000%\n",
            "step 2000, elapsed time 311.96 seconds, training accuracy 98.000%\n",
            "step 2100, elapsed time 327.51 seconds, training accuracy 100.000%\n",
            "step 2200, elapsed time 343.28 seconds, training accuracy 100.000%\n",
            "step 2300, elapsed time 358.83 seconds, training accuracy 98.000%\n",
            "step 2400, elapsed time 374.37 seconds, training accuracy 100.000%\n",
            "step 2500, elapsed time 389.95 seconds, training accuracy 94.000%\n",
            "step 2600, elapsed time 405.51 seconds, training accuracy 100.000%\n",
            "step 2700, elapsed time 421.07 seconds, training accuracy 98.000%\n",
            "step 2800, elapsed time 436.68 seconds, training accuracy 100.000%\n",
            "step 2900, elapsed time 452.23 seconds, training accuracy 100.000%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j8Mm5BfICEm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "068e325f-dfd4-4583-a7b9-9d8ea235b19c"
      },
      "source": [
        "# Display summary \n",
        "#     Time to train\n",
        "end_time = time.time()\n",
        "print(\"Total training time for {0} batches: {1:.2f} seconds\".format(i+1, end_time-start_time))\n",
        "\n",
        "#     Accuracy on test data\n",
        "print(\"Test accuracy {0:.3f}%\".format(accuracy.eval(feed_dict={\n",
        "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})*100.0))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total training time for 3000 batches: 497.27 seconds\n",
            "Test accuracy 98.280%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t8_zHFCMETL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}