{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_neural_network_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN7Jn2yWm0BsdAkyNlO2HXm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krips2398/tensorflow_learnings/blob/master/Deep_neural_network_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxtcQmkt276f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CONVOLUTIONAL NEURAL NETWORKS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIcale663gXg",
        "colab_type": "text"
      },
      "source": [
        "It inspects the subsets of images, learns features of image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqLrWGW33cLU",
        "colab_type": "code",
        "outputId": "f1dbe756-de99-4ebd-9007-395dd274f322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "!pip install tensorflow==1.14.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.28.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (46.1.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuo5-fIh47BE",
        "colab_type": "code",
        "outputId": "b916c62c-dd0b-4495-dca9-e1f507f2fb28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        }
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpCZQY1j5Ps7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA11-SX_5miX",
        "colab_type": "code",
        "outputId": "322ae8d3-58b7-4b14-a9fa-ea8c37ce1918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-a839aeb82f4b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdk4PlyGIfc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define a log path to tensorboard log files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYHQ243OIflq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logPath =\"./tb_logs/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a1y9kOGIp75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#   Adds summaries statistics for use in TensorBoard visualization.  \n",
        "#      From https://www.tensorflow.org/get_started/summaries_and_tensorboard\n",
        "def variable_summaries(var):\n",
        "   with tf.name_scope('summaries'):\n",
        "    mean = tf.reduce_mean(var)\n",
        "    tf.summary.scalar('mean', mean)\n",
        "    with tf.name_scope('stddev'):\n",
        "      stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
        "    tf.summary.scalar('stddev', stddev)\n",
        "    tf.summary.scalar('max', tf.reduce_max(var))\n",
        "    tf.summary.scalar('min', tf.reduce_min(var))\n",
        "    tf.summary.histogram('histogram', var)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uySVCQSIyPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gONyXdLIyWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2Zp2v1p5oPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzU-AkPeIeft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53QVowDK50vV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using Interactive session as default session so that we really do not need to go back and pass the session every single time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJF0LDE_8FOA",
        "colab_type": "text"
      },
      "source": [
        "Defining the placeholders --> x- represents the 28*28 dimensional vector\n",
        "y_ is the actual label of the image-->\n",
        "[0,1,0,0,0,0,0,0,0,0,0] - represents digit 1\n",
        "Similarly [0,0,1,0,0,0,0,0,0,0,0] - represents digit 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKycXC4wI2KC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Also define the name scopes for different input data that we are using"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwec55xJI-JW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nEIHUKN7_zQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope(\"MNIST_Input\"):\n",
        "  x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\n",
        "  y_ = tf.placeholder(tf.float32, [None, 10], name=\"y_\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1rU4OIp8oaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change the MNIST input data from a list of values to a 28 pixel X 28 pixel X 1 grayscale value cube\n",
        "#    which the Convolution NN can use.\n",
        "with tf.name_scope(\"Input_Reshape\"):\n",
        "  x_image = tf.reshape(x, [-1,28,28,1], name=\"x_image\")\n",
        "  tf.summary.image('input_img', x_image, 5)\n",
        "#here -1 is obviously not a valid dimension --> it is simply used as a flag to reduce it or split the image into 28*28*1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lubN4M99-Cuw",
        "colab_type": "text"
      },
      "source": [
        "**RELU as Activation Function**\n",
        "\n",
        "\n",
        "> ReLU stands for rectified linear unit, and is a type of activation function. Mathematically, it is defined as y = max(0, x).\n",
        "\n",
        "\n",
        "> https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U15auNo5AsTl",
        "colab_type": "text"
      },
      "source": [
        "**truncated_normal**\n",
        "\n",
        "> https://docs.w3cub.com/tensorflow~python/tf/truncated_normal/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMvkV5Xy9IJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define helper functions to created weights and baises variables, and convolution, and pooling layers\n",
        "#   We are using RELU as our activation function.  These must be initialized to a small positive number \n",
        "#   and with some noise so you don't end up going to zero when comparing diffs\n",
        "def weight_variable(shape,name=None):\n",
        "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
        "    return tf.Variable(initial, name=name)\n",
        "\n",
        "def bias_variable(shape,name=None):\n",
        "    initial = tf.constant(0.1, shape=shape)\n",
        "    return tf.Variable(initial, name=name)\n",
        "\n",
        "#We are basically picking up the random values for weights and bias variables\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuRNivmiB0OV",
        "colab_type": "text"
      },
      "source": [
        "**Convolution and Pooling**\n",
        "\n",
        "> https://stackoverflow.com/questions/34619177/what-does-tf-nn-conv2d-do-in-tensorflow\n",
        "\n",
        "\n",
        "> Pooling all the conv values to prevent overfitting\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Bfi274oBuOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#   Convolution and Pooling - we do Convolution, and then pooling to control overfitting\n",
        "def conv2d(x, W, name=None):\n",
        "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME', name=name)\n",
        "\n",
        "def max_pool_2x2(x,name=None):\n",
        "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
        "                        strides=[1, 2, 2, 1], padding='SAME', name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PCj4QXdFIYw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "271adeeb-d46f-4c6e-eb5e-3b734c32a97c"
      },
      "source": [
        "# Define layers in the NN\n",
        "\n",
        "# 1st Convolution layer\n",
        "# 32 features for each 5X5 patch of the image\n",
        "with tf.name_scope('Conv1'):\n",
        "  with tf.name_scope('weights'):\n",
        "    W_conv1 = weight_variable([5, 5, 1, 32])\n",
        "    variable_summaries(W_conv1)\n",
        "  with tf.name_scope('baises'):\n",
        "    b_conv1 = bias_variable([32])\n",
        "    variable_summaries(b_conv1)\n",
        "   #Do convolution on images, add bias and push through RELU activation\n",
        "  conv1_wx_b = conv2d(x_image, W_conv1,name=\"conv2d\") + b_conv1\n",
        "  tf.summary.histogram('conv1_wx_b', conv1_wx_b)\n",
        "  h_conv1 = tf.nn.relu(conv1_wx_b, name=\"relu\")\n",
        "  tf.summary.histogram('h_conv1', h_conv1)\n",
        "  # take results and run through max_pool\n",
        "  h_pool1 = max_pool_2x2(h_conv1, name=\"pool\")\n",
        "\n",
        "\n",
        "# 2nd Convolution layer\n",
        "with tf.name_scope('Conv2'):\n",
        "# Process the 32 features from Convolution layer 1, in 5 X 5 patch.  return 64 features weights and biases\n",
        "    with tf.name_scope('weights'):\n",
        "        W_conv2 = weight_variable([5, 5, 32, 64], name=\"weight\")\n",
        "        variable_summaries(W_conv2)\n",
        "    with tf.name_scope('biases'):\n",
        "        b_conv2 = bias_variable([64], name=\"bias\")\n",
        "        variable_summaries(b_conv2)\n",
        "    # Do convolution of the output of the 1st convolution layer.  Pool results \n",
        "    conv2_wx_b = conv2d(h_pool1, W_conv2, name=\"conv2d\") + b_conv2\n",
        "    tf.summary.histogram('conv2_wx_b', conv2_wx_b)\n",
        "    h_conv2 = tf.nn.relu(conv2_wx_b, name=\"relu\")\n",
        "    tf.summary.histogram('h_conv2', h_conv2)\n",
        "    h_pool2 = max_pool_2x2(h_conv2, name=\"pool\")\n",
        "\n",
        "with tf.name_scope('FC'):\n",
        "    # Fully Connected Layer\n",
        "    W_fc1 = weight_variable([7 * 7 * 64, 1024], name=\"weight\")\n",
        "    b_fc1 = bias_variable([1024], name=\"bias\")\n",
        "    #   Connect output of pooling layer 2 as input to full connected layer\n",
        "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
        "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1, name=\"relu\")\n",
        "\n",
        "# dropout some neurons to reduce overfitting\n",
        "keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")  # get dropout probability as a training input.\n",
        "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
        "\n",
        "with tf.name_scope(\"Readout\"):\n",
        "# Readout layer\n",
        "    W_fc2 = weight_variable([1024, 10], name=\"weight\")\n",
        "    b_fc2 = bias_variable([10], name=\"bias\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-16-2a464759b888>:43: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-qghI-oFVl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define model\n",
        "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlDvwzjLFY-S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "569e0df0-c5dd-4651-9565-8014644c2dfe"
      },
      "source": [
        "# Loss measurement\n",
        "with tf.name_scope(\"cross_entropy\"):\n",
        "  cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_conv, labels=y_))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-18-9fffafaf6e1d>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5WCvl3vFcDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss optimization\n",
        "with tf.name_scope(\"loss_optimizer\"):\n",
        "  train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_comoZ56FjIN",
        "colab_type": "text"
      },
      "source": [
        "**Adam Optimization**\n",
        "\n",
        "> Something better than gradient descent\n",
        "\n",
        "\n",
        "> https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTIPBSxAFhCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope(\"accuracy\"):\n",
        "  # What is correct\n",
        "  correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
        "  # How accurate is it?\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUDpwpBXL16g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50a450cd-467e-494a-ca8a-8b84298b0b1e"
      },
      "source": [
        "tf.summary.scalar(\"cross_entropy_scl\", cross_entropy)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'cross_entropy_scl:0' shape=() dtype=string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hac7eeTCL9cb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48659082-a8a1-4526-f670-a40a064e9a5b"
      },
      "source": [
        "tf.summary.scalar(\"training_accuracy\",accuracy)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'training_accuracy:0' shape=() dtype=string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63KDSK-xHwA9",
        "colab_type": "code",
        "outputId": "e76b4d9e-001e-47a4-aaf0-e5d80e269787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'accuracy/Mean:0' shape=() dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGO2AU2mHxCH",
        "colab_type": "code",
        "outputId": "d45da8d8-bd81-4913-cf33-080f8fc6df57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct_prediction"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'accuracy/Equal:0' shape=(?,) dtype=bool>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sD8JzekMGK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tensorboard - merge summaries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRSDPUNuMLaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summarize_all = tf.summary.merge_all()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNlc_SGYH1R1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "import time\n",
        "\n",
        "#  define number of steps and how often we display progress\n",
        "num_steps = 3000\n",
        "display_every = 100\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg90dLNZH7iM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start timer\n",
        "start_time = time.time()\n",
        "end_time = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GelvWgEdKN6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTrI8qaEKOnU",
        "colab_type": "text"
      },
      "source": [
        "Whwn u get `FailedPreconditionError: Attempting to use uninitialized in Tensorflow` - initialize all the variables declared like below --> run the global initializer\n",
        "Stack overflow link https://stackoverflow.com/questions/34001922/failedpreconditionerror-attempting-to-use-uninitialized-in-tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBx1u1MjKCXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcSfquNuMVEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TB - Write the default graph out so we can view it's structure\n",
        "tbWriter = tf.summary.FileWriter(logPath, sess.graph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5uZny1iH9ye",
        "colab_type": "code",
        "outputId": "be29375a-5abf-4109-f052-a59563010243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Train the model\n",
        "import time\n",
        "\n",
        "#  define number of steps and how often we display progress\n",
        "num_steps = 2000\n",
        "display_every = 100\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "end_time = time.time()\n",
        "for i in range(num_steps):\n",
        "    batch = mnist.train.next_batch(50)\n",
        "    _, summary = sess.run([train_step, summarize_all], feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
        "\n",
        "\n",
        "    # Periodic status display\n",
        "    if i%display_every == 0:\n",
        "        train_accuracy = accuracy.eval(feed_dict={\n",
        "            x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
        "        end_time = time.time()\n",
        "        print(\"step {0}, elapsed time {1:.2f} seconds, training accuracy {2:.3f}%\".format(i, end_time-start_time, train_accuracy*100.0))\n",
        "        # write summary to log\n",
        "        tbWriter.add_summary(summary,i)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, elapsed time 0.54 seconds, training accuracy 8.000%\n",
            "step 100, elapsed time 26.92 seconds, training accuracy 88.000%\n",
            "step 200, elapsed time 53.42 seconds, training accuracy 86.000%\n",
            "step 300, elapsed time 79.97 seconds, training accuracy 98.000%\n",
            "step 400, elapsed time 106.35 seconds, training accuracy 90.000%\n",
            "step 500, elapsed time 132.65 seconds, training accuracy 92.000%\n",
            "step 600, elapsed time 159.08 seconds, training accuracy 96.000%\n",
            "step 700, elapsed time 185.48 seconds, training accuracy 98.000%\n",
            "step 800, elapsed time 211.87 seconds, training accuracy 88.000%\n",
            "step 900, elapsed time 238.26 seconds, training accuracy 88.000%\n",
            "step 1000, elapsed time 264.64 seconds, training accuracy 98.000%\n",
            "step 1100, elapsed time 291.15 seconds, training accuracy 92.000%\n",
            "step 1200, elapsed time 317.48 seconds, training accuracy 98.000%\n",
            "step 1300, elapsed time 343.98 seconds, training accuracy 100.000%\n",
            "step 1400, elapsed time 370.41 seconds, training accuracy 96.000%\n",
            "step 1500, elapsed time 396.89 seconds, training accuracy 100.000%\n",
            "step 1600, elapsed time 423.41 seconds, training accuracy 98.000%\n",
            "step 1700, elapsed time 449.87 seconds, training accuracy 100.000%\n",
            "step 1800, elapsed time 476.31 seconds, training accuracy 100.000%\n",
            "step 1900, elapsed time 502.71 seconds, training accuracy 98.000%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j8Mm5BfICEm",
        "colab_type": "code",
        "outputId": "3448c041-5f78-4865-888f-6ddb35bf570f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Display summary \n",
        "#     Time to train\n",
        "end_time = time.time()\n",
        "print(\"Total training time for {0} batches: {1:.2f} seconds\".format(i+1, end_time-start_time))\n",
        "\n",
        "#     Accuracy on test data\n",
        "print(\"Test accuracy {0:.3f}%\".format(accuracy.eval(feed_dict={\n",
        "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})*100.0))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total training time for 2000 batches: 612.07 seconds\n",
            "Test accuracy 97.740%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlzl9Y8KU7Oq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "26cb6f1e-0ffc-464d-d5c7-44edcfb9f832"
      },
      "source": [
        "!pip install tensorboard==1.14.0"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboard==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.14.0) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.14.0) (46.1.3)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.14.0) (1.28.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.14.0) (1.18.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.14.0) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBHeDdcVT0e5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "8c8fddfe-7965-48db-ac6b-05bc2d867a4e"
      },
      "source": [
        "tensorboard.__version__"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-8040dc1e0e9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tensorboard' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t8_zHFCMETL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "abbadeb4-c8f8-4208-8acd-839673509a40"
      },
      "source": [
        "!tensorboard --logdir tb_logs"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/tensorboard\", line 8, in <module>\n",
            "    sys.exit(run_main())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/main.py\", line 59, in run_main\n",
            "    program.get_default_assets_zip_provider())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 144, in __init__\n",
            "    self.plugin_loaders = [make_loader(p) for p in plugins]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 144, in <listcomp>\n",
            "    self.plugin_loaders = [make_loader(p) for p in plugins]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 143, in make_loader\n",
            "    raise ValueError(\"Not a TBLoader or TBPlugin subclass: %s\" % plugin)\n",
            "ValueError: Not a TBLoader or TBPlugin subclass: <class 'tensorboard_plugin_wit.wit_plugin_loader.WhatIfToolPluginLoader'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-9u7Ke-Q10W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}